cluster-alerts.yaml: |
  groups:
  - name: kube-apiserver.rules
    rules:
    - alert: NoKubeAPIServerExists
      expr: count(up{job="kube-apiserver"})==0
      for: 2m
      labels:
        job: kube-apiserver
        severity: blocker
      annotations:
        description: Prometheus can't find a kube-apiserver target to scrape.
        summary: No Kube API server pod exists
    - alert: kubeAPIServerDown
      expr: absent(up{job="kube-apiserver"}==1)
      for: 2m
      labels:
        job: kube-apiserver
        severity: critical
      annotations:
        description: Prometheus can't scape metrics from API server(s).
        summary: Kube API server down

  - name: kube-controller-manager.rules
    rules:
    - alert: NoControllerManagerExists
      expr: count(up{job="kube-controller-manager"})==0
      for: 2m
      labels:
        job: kube-controller-manager
        severity: blocker
      annotations:
        description: Prometheus can't find a kube-controller-manager target to scrape.
        summary: No Kube Controller Manager pod exists
    - alert: kubeControllerManagerDown
      expr: absent(up{job="kube-controller-manager"}==1)
      for: 2m
      labels:
        job: kube-controller-manager
        severity: critical
      annotations:
        description: Prometheus can't scape metrics from kube-controller-manager(s).
        summary: Kube Controller Manager down

  - name: kube-scheduler.rules
    rules:
    - alert: NoSchedulerExists
      expr: count(up{job="kube-scheduler"})==0
      for: 2m
      labels:
        job: kube-scheduler
        severity: blocker
      annotations:
        description: Prometheus can't find a kube-scheduler target to scrape.
        summary: No Kube Scheduler pod exists
    - alert: kubeSchedulerDown
      expr: absent(up{job="kube-scheduler"}==1)
      for: 2m
      labels:
        job: kube-scheduler
        severity: critical
      annotations:
        description: Prometheus can't scape metrics from kube-scheduler(s).
        summary: Kube Scheduler down

  - name: etcd.rules
    rules:
    - alert: NoEtcdExists
      expr: count(up{job="etcd"})==0
      for: 2m
      labels:
        job: etcd
        severity: blocker
      annotations:
        description: Prometheus can't find an etcd target to scrape.
        summary: No Etcd pod exists
    - alert: etcdDown
      expr: absent(up{job="etcd"}==1)
      for: 2m
      labels:
        job: etcd
        severity: critical
      annotations:
        description: Prometheus can't scape metrics from etcd(s).
        summary: Etcd down

  - name: kube-dns.rules
    rules:
    - alert: NoKubeDNSExists
      expr: count(up{job="kube-dns"})==0
      for: 5m
      labels:
        job: kube-dns
        severity: critical
      annotations:
        description: Prometheus can't find a kube-dns target to scrape.
        summary: No KubeDNS pod exists
    - alert: kubeDNSDown
      expr: absent(up{job="kube-dns"}==1)
      for: 2m
      labels:
        job: kube-dns
        severity: critical
      annotations:
        description: Prometheus can't scape metrics from kube-dns.
        summary: KubeDNS down

  - name: grafana.rules
    rules:
    - alert: GrafanaDown
      expr: absent(up{job="grafana"}==1)
      for: 10m
      labels:
        job: grafana
        severity: warning
      annotations:
        description: Prometheus can`t scrape metrics from a Grafana pod for at least 10 minutes.
        summary: No Grafana instance is running, no dashboards available

  - name: node-kubelet.rules
    rules:
    - alert: NodeCountCritical
      expr: count(up{job="kubernetes-nodes"})<2
      for: 2m
      labels:
        job: kubernetes-nodes
        severity: critical
      annotations:
        description: Prometheus can only scrape metrics from less then two kubelets.
        summary: Count of nodes is critical